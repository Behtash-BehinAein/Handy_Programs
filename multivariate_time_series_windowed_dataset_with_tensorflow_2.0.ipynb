{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multivariate_time_series_windowed_dataset_with_tensorflow_2.0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_jI67FG5F9Hc","colab_type":"code","outputId":"0274b96b-72d4-4ba7-a601-1e024645568a","executionInfo":{"status":"ok","timestamp":1576680918852,"user_tz":480,"elapsed":73655,"user":{"displayName":"Behtash Behin-Aein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAdectYP67EuQjUiyZ70pPsYs1aAkhncI44kX14Eg=s64","userId":"01072795337096734450"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install tensorflow==2.0.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n","\u001b[K     |████████████████████████████████| 86.3MB 40kB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n","Collecting tensorflow-estimator<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n","\u001b[K     |████████████████████████████████| 450kB 48.0MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n","Collecting tensorboard<2.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (42.0.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/83/3cb31033e1ea0bdb8991b6ef327a5bf4960bd3dd31ff355881bfb0ddf199/google_auth-1.9.0-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n","\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.9.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: google-auth 1.4.2\n","    Uninstalling google-auth-1.4.2:\n","      Successfully uninstalled google-auth-1.4.2\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed google-auth-1.9.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"pmoH7nhcF1rV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"69f5bdea-1415-418f-f32f-d2861c607120","executionInfo":{"status":"ok","timestamp":1576680955426,"user_tz":480,"elapsed":389,"user":{"displayName":"Behtash Behin-Aein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAdectYP67EuQjUiyZ70pPsYs1aAkhncI44kX14Eg=s64","userId":"01072795337096734450"}}},"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Cc5FPiwkK_k","colab_type":"text"},"source":["# Method to create windowed dataset for training data"]},{"cell_type":"code","metadata":{"id":"OiyeQDkAEZC6","colab_type":"code","colab":{}},"source":["'''\n","# Create windowed-dataset \n","'''\n","def train_windowed_ds(df: 'DataFrame',  win_w = 2, win_shift = 1, shuffle_size=100, batch_size=32):\n","    '''\n","    - Takes in a Pandas dataframe of features and a targets(labels) column\n","      The rows of input dataframe should represent \"time\" instances in chronological order\n","      Function generates a tf-windowed-dataset of features/targets\n","      - Targets must be the last column of the DataFrame \n","    \n","    - win_w     : user-defined 'int' that determines the width of sliding window\n","    - win_shift : user-defined 'int' that determines forward shift of the sliding window \n","\n","    - Returns: \n","        A tensorflow dataset \n","          With features:\n","            - 0th dimension representing the sliding-window-index (aka sample-index) \n","            - 1st dimension representing the width of the sliding window (no. time-steps)\n","            - 2nd dimension representing the number of features in each sliding window (all equal)\n","          And targets: \n","            - If win_w = 1, then each time-step (w/ multiple features) has a target \n","            - If win_w >1 , then each sliding-window (w/ multiple features) with multiple time-steps has a target\n","    '''\n","    # Extract fatures and lables into two Numpy arrays \n","    X = df.iloc[:,:-1].values                     # Features \n","    y = df.iloc[:, -1].values.reshape((-1,1))     # Targets\n","\n","\n","    # This transpose is taken to make the following dataset operations simpler \n","    arr = X.T\n","\n","    # Number of time instances and number of features \n","    n_features, n_time  = arr.shape\n","\n","    if win_w > n_time:\n","        raise ValueError(f'The width of the given time-window:{win_w} is not <= total number of time-steps: {n_time}.') \n","\n","    # Define the stride of the input elements for the sliding window \n","    n_stride = 1\n","    # Calculate the total number of sliding windows\n","    n_win = (n_time - win_w)//n_stride + 1\n","\n","    # Create a dataset from 2D numpy array of features \n","    dsF = tf.data.Dataset.from_tensor_slices(arr)\n","\n","    # Create a dataset from 2D (n by 1) numpy array of targets \n","    dsL = tf.data.Dataset.from_tensor_slices(y)\n","\n","    # Generate a tf dataset with flattened rolling windows for each feature \n","    def generate_flattened_rolling_windows(ds):\n","        ds = tf.data.Dataset.from_tensor_slices(ds)\n","        ds = ds.window(size= win_w, shift=win_shift, stride = n_stride , drop_remainder=True)\n","        ds = ds.flat_map(lambda x: x.batch(win_w)) \n","        ds = ds.unbatch()\n","        ds = ds.batch(n_win*win_w)\n","        return ds\n","    dsF = dsF.flat_map(generate_flattened_rolling_windows)\n","    # ---------------------------------------------------------------------\n","\n","    # Generate a tf dataset with flattened rolling windows for the targets\n","    def generate_rolling_windows(ds):\n","        ds = ds.window(size= win_w, shift=win_shift, stride = n_stride , drop_remainder=True)\n","        ds = ds.flat_map(lambda x: x.batch(win_w)) \n","        if win_w !=1:\n","            ds = ds.map(lambda x: x[-1]) \n","        return ds\n","    dsL = generate_rolling_windows(dsL)\n","    # ---------------------------------------------------------------------\n","\n","    # Create a 3D numpy array of windowed time-series features  \n","    features =  np.array( [ele.numpy() for ele in dsF] ).T.reshape((n_win , win_w, n_features))\n","    # Create a 3D numpy array of windowed targets   \n","    labels   =  np.array([win.numpy() for win in dsL])\n","\n","    # Reduce dimensions if the sliding window has unit width i.e. win_w = 1 \n","    if win_w == 1:\n","        features = features.reshape((n_win, n_features))\n","        labels = labels.reshape((-1,1))\n","\n","    # Form a tensorflow dataset from numpy feartues/labels \n","    dataset = tf.data.Dataset.from_tensor_slices((features, labels)) \n","\n","    # Shuffle, batch and prefetch the data \n","    dataset = dataset.shuffle(buffer_size= shuffle_size, seed=1).batch(batch_size).prefetch(1)\n","    return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJcy52RWkRNT","colab_type":"text"},"source":["# Method to create windowed dataset for validation data"]},{"cell_type":"code","metadata":{"id":"0THN3ILtiiaa","colab_type":"code","colab":{}},"source":["'''\n","# Create windowed-dataset \n","'''\n","def valid_windowed_ds(df: 'DataFrame',  win_w = 2, win_shift = 1, batch_size=32):\n","    '''\n","    - Takes in a Pandas dataframe of features and a targets(labels) column\n","      The rows of input dataframe should represent \"time\" instances in chronological order\n","      Function generates a tf-windowed-dataset of features/targets\n","      - Targets must be the last column of the DataFrame \n","    \n","    - win_w     : user-defined 'int' that determines the width of sliding window\n","    - win_shift : user-defined 'int' that determines forward shift of the sliding window \n","\n","    - Returns: \n","        A tensorflow dataset \n","          With features:\n","            - 0th dimension representing the sliding-window-index (aka sample-index) \n","            - 1st dimension representing the width of the sliding window (no. time-steps)\n","            - 2nd dimension representing the number of features in each sliding window (all equal)\n","          And targets: \n","            - If win_w = 1, then each time-step (w/ multiple features) has a target \n","            - If win_w >1 , then each sliding-window (w/ multiple features) with multiple time-steps has a target\n","    '''\n","    # Extract fatures and targets into two Numpy arrays \n","    X = df.iloc[:,:-1].values                     # Features \n","    y = df.iloc[:, -1].values.reshape((-1,1))     # Targets\n","\n","\n","    # This transpose is taken to make the following dataset operations simpler \n","    arr = X.T\n","\n","    # Number of time instances and number of features \n","    n_features, n_time  = arr.shape\n","\n","    if win_w > n_time:\n","        raise ValueError(f'The width of the given time-window:{win_w} is not <= total number of time-steps: {n_time}.') \n","\n","    # Define the stride of the input elements for the sliding window \n","    n_stride = 1\n","    # Calculate the total number of sliding windows\n","    n_win = (n_time - win_w)//n_stride + 1\n","\n","    # Create a dataset from 2D numpy array of features \n","    dsF = tf.data.Dataset.from_tensor_slices(arr)\n","\n","    # Create a dataset from 2D (n by 1) numpy array of targets \n","    dsL = tf.data.Dataset.from_tensor_slices(y)\n","\n","    # Generate a tf dataset with flattened rolling windows for each feature \n","    def generate_flattened_rolling_windows(ds):\n","        ds = tf.data.Dataset.from_tensor_slices(ds)\n","        ds = ds.window(size= win_w, shift=win_shift, stride = n_stride , drop_remainder=True)\n","        ds = ds.flat_map(lambda x: x.batch(win_w)) \n","        ds = ds.unbatch()\n","        ds = ds.batch(n_win*win_w)\n","        return ds\n","    dsF = dsF.flat_map(generate_flattened_rolling_windows)\n","    # ---------------------------------------------------------------------\n","\n","    # Generate a tf dataset with flattened rolling windows for the targets\n","    def generate_rolling_windows(ds):\n","        ds = ds.window(size= win_w, shift=win_shift, stride = n_stride , drop_remainder=True)\n","        ds = ds.flat_map(lambda x: x.batch(win_w)) \n","        if win_w !=1:\n","            ds = ds.map(lambda x: x[-1]) \n","        return ds\n","    dsL = generate_rolling_windows(dsL)\n","    # ---------------------------------------------------------------------\n","\n","    # Create a 3D numpy array of windowed time-series features  \n","    features =  np.array( [ele.numpy() for ele in dsF] ).T.reshape((n_win , win_w, n_features))\n","    # Create a 3D numpy array of windowed targets   \n","    labels   =  np.array([win.numpy() for win in dsL])\n","\n","    # Reduce dimensions if the sliding window has unit width i.e. win_w = 1 \n","    if win_w == 1:\n","        features = features.reshape((n_win, n_features))\n","        labels = labels.reshape((-1,1))\n","\n","    # Form a tensorflow dataset from numpy feartues/labels \n","    dataset = tf.data.Dataset.from_tensor_slices((features, labels)) \n","\n","    # Shuffle, batch and prefetch the data \n","    dataset = dataset.batch(batch_size).prefetch(1)\n","    return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BabDRSAEUUO2","colab_type":"text"},"source":["# Example "]},{"cell_type":"code","metadata":{"id":"q1XWOb67Fo-q","colab_type":"code","outputId":"8a2e8d7f-6fa8-4b8c-8215-f2402e2091d2","executionInfo":{"status":"ok","timestamp":1576681863289,"user_tz":480,"elapsed":716,"user":{"displayName":"Behtash Behin-Aein","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAdectYP67EuQjUiyZ70pPsYs1aAkhncI44kX14Eg=s64","userId":"01072795337096734450"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Create a contrived dataset \n","data   = np.array([[1,  10, 100, 1000],\n","                   [2,  20, 200, 2000],\n","                   [3,  30, 300, 3000],\n","                   [4,  40, 400, 4000], \n","                   [5,  50, 500, 5000],\n","                   [6,  60, 600, 6000],\n","                   [7,  70, 700, 7000],\n","                   [8,  80, 800, 8000],\n","                   [9,  90, 900, 9000],\n","                   [10,  100, 1000, 10000],\n","                   ])\n","\n","df = pd.DataFrame(data, columns=['F1', 'F2', 'F3', 'Target'])\n","\n","train_valid_split = 0.7\n","train, valid = df.iloc[:int(train_valid_split*len(df)),:] , df.iloc[int(train_valid_split*len(df)):,:]\n","print('\\nThis is the original dataframe (contrived data for illustration only): ')\n","display(df)\n","print('\\nThis is the training data : ')\n","display(train)\n","print('\\nThis is the validation data : ')\n","display(valid)\n","\n","\n","# Create the train windowed dataset \n","train_dataset = train_windowed_ds(train, win_w = 3, win_shift = 1, shuffle_size=3 , batch_size=10)\n","print('--'*20)\n","print('\\nThis is the shuffled train windowed dataset: ')\n","\n","\n","for x,y in train_dataset:\n","    print('features = ', x.numpy()[:])\n","    print('labels = ', y.numpy()[:])\n","\n","# -----------------------------------------------------------------------------------------\n","\n","# Create the valid windowed dataset \n","valid_dataset = valid_windowed_ds(valid, win_w = 2, win_shift = 1, batch_size=10)\n","print('--'*20)\n","print('\\nThis is the valid windowed dataset: ')\n","\n","for x,y in valid_dataset:\n","    print('features = ', x.numpy())\n","    print('labels = ', y.numpy())"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\n","This is the original dataframe (contrived data for illustration only): \n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>F1</th>\n","      <th>F2</th>\n","      <th>F3</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>100</td>\n","      <td>1000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>200</td>\n","      <td>2000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>30</td>\n","      <td>300</td>\n","      <td>3000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>40</td>\n","      <td>400</td>\n","      <td>4000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>50</td>\n","      <td>500</td>\n","      <td>5000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>60</td>\n","      <td>600</td>\n","      <td>6000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>70</td>\n","      <td>700</td>\n","      <td>7000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>80</td>\n","      <td>800</td>\n","      <td>8000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>90</td>\n","      <td>900</td>\n","      <td>9000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>100</td>\n","      <td>1000</td>\n","      <td>10000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   F1   F2    F3  Target\n","0   1   10   100    1000\n","1   2   20   200    2000\n","2   3   30   300    3000\n","3   4   40   400    4000\n","4   5   50   500    5000\n","5   6   60   600    6000\n","6   7   70   700    7000\n","7   8   80   800    8000\n","8   9   90   900    9000\n","9  10  100  1000   10000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","This is the training data : \n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>F1</th>\n","      <th>F2</th>\n","      <th>F3</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>100</td>\n","      <td>1000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>200</td>\n","      <td>2000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>30</td>\n","      <td>300</td>\n","      <td>3000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>40</td>\n","      <td>400</td>\n","      <td>4000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>50</td>\n","      <td>500</td>\n","      <td>5000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>60</td>\n","      <td>600</td>\n","      <td>6000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>70</td>\n","      <td>700</td>\n","      <td>7000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   F1  F2   F3  Target\n","0   1  10  100    1000\n","1   2  20  200    2000\n","2   3  30  300    3000\n","3   4  40  400    4000\n","4   5  50  500    5000\n","5   6  60  600    6000\n","6   7  70  700    7000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","This is the validation data : \n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>F1</th>\n","      <th>F2</th>\n","      <th>F3</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>80</td>\n","      <td>800</td>\n","      <td>8000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>90</td>\n","      <td>900</td>\n","      <td>9000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>100</td>\n","      <td>1000</td>\n","      <td>10000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   F1   F2    F3  Target\n","7   8   80   800    8000\n","8   9   90   900    9000\n","9  10  100  1000   10000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["----------------------------------------\n","\n","This is the shuffled train windowed dataset: \n","features =  [[[  2  20 200]\n","  [  3  30 300]\n","  [  4  40 400]]\n","\n"," [[  4  40 400]\n","  [  5  50 500]\n","  [  6  60 600]]\n","\n"," [[  1  10 100]\n","  [  2  20 200]\n","  [  3  30 300]]\n","\n"," [[  5  50 500]\n","  [  6  60 600]\n","  [  7  70 700]]\n","\n"," [[  3  30 300]\n","  [  4  40 400]\n","  [  5  50 500]]]\n","labels =  [[4000]\n"," [6000]\n"," [3000]\n"," [7000]\n"," [5000]]\n","----------------------------------------\n","\n","This is the valid windowed dataset: \n","features =  [[[   8   80  800]\n","  [   9   90  900]]\n","\n"," [[   9   90  900]\n","  [  10  100 1000]]]\n","labels =  [[ 9000]\n"," [10000]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"65gtaxpqt4Kh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}